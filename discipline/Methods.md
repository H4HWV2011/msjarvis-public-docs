# Polymathmatic Geography: Methods

Polymathmatic geography is defined as much by its *methods* as by its objects of study. This document outlines a short menu of canonical methods and how results are interpreted. The guiding rule is simple: every method must ultimately return to lived geographies and communities, not just to performance metrics or abstract models.

---

## 1. Field‑Anchored Inquiry

Polymathmatic work begins in specific worlds: towns, watersheds, platforms, congregations, ecosystems, networks. Field‑anchored inquiry treats these as primary texts.

**Typical practices**

- Walking, observing, and documenting physical and digital infrastructures (roads, rail, fiber, platforms, data centers, churches, clinics, cemeteries).  
- Interviews, oral histories, and ethnography with residents, workers, organizers, and officials.  
- Archival and policy research on land use, extraction, regulation, resistance, and reform.  
- Identifying early, with communities, which relations or sites must not be mapped or datafied at all.

**Interpretation**

Findings are not treated as “context” for later models, but as co‑equal sources of truth. Models and metrics are judged partly by whether they resonate with, and are accountable to, what people in these places recognize as real, and partly by whether they respect explicit refusals and boundaries voiced in the field.

---

## 2. Econophysics and Quantitative Spatial Modeling

Mathematical tools from physics and quantitative economics are used to describe flows of capital, risk, energy, attention, and information in space.

**Typical practices**

- Applying econophysics and statistical mechanics to spatial economic data (e.g., distributions of income, debt, rents, ownership, transaction volumes).  
- Building spatially explicit models of extraction and accumulation (e.g., gravity models, diffusion processes, agent‑based simulations on landscapes and networks).  
- Computing measures such as entropy, concentration indices, and inequality metrics for specific regions or networks.  
- Comparing local measures to patterns associated with maximopolies and megaopolies (e.g., long‑range capital pulls, logistics and attention funnels) to see where a region is being wired into external fields.

**Interpretation**

Numbers are always tied back to places and stories: a change in an entropy measure must be interpretable as a change in how people live, decide, and endure in a given geography, not just as an optimization score. Quantitative results are evaluated against community accounts of extraction, precarity, and resilience, and against clear norms about what kinds of economic behavior are unacceptable.

---

## 3. Network and Graph Models of Extraction and Cooperation

Networks and graphs are used to represent who is connected to whom, on what terms, across physical, digital, institutional, and spiritual spaces.

**Typical practices**

- Constructing multi‑layer networks linking firms, households, infrastructures, institutions, platforms, and ecosystems.  
- Identifying hubs, peripheries, corridors, bottlenecks, and fractures in networks of value, decision‑making, narrative, and information.  
- Modeling “credit basins,” “resilience corridors,” and “extraction funnels” in mutual credit systems, barter networks, supply chains, and digital platforms.  
- Explicitly mapping where global actors (e.g., asset managers, platform companies, logistics giants) sit in the graph relative to local commons, congregations, and governments.

**Interpretation**

Network results are interpreted as maps of actual constraint and possibility: who can reach help or opportunity in one or two steps, who is structurally isolated, who is over‑exposed to shocks, and where external power is wired into local life. The aim is to change those structures in ways communities define as just and life‑giving, and to avoid replicating network patterns that resemble known extraction geometries.

---

## 4. Participatory Mapping and Co‑Design

People who inhabit a place or system are treated as co‑researchers and co‑designers, not just as data sources.

**Typical practices**

- Participatory mapping workshops where residents draw their own maps of danger, care, extraction, and hope (e.g., where debt collectors come from, where mutual aid flows, where spiritual anchors sit).  
- Co‑design sessions for infrastructures (e.g., local credit schemes, commons platforms, AI governance rules) in which community members help set parameters, rules, and safeguards.  
- Ongoing feedback loops (assemblies, councils, digital forums) where community interpretations of data and models can revise both methods and designs.  
- Creating formal avenues for refusal, appeal, and redesign when people experience a tool as harmful or misaligned with covenant, law, or custom.

**Interpretation**

Success is not defined only by technical performance (throughput, accuracy, efficiency) but by perceived legitimacy, alignment with community values, and concrete shifts in power and safety as experienced by participants. Designs that produce efficient metrics but are rejected by those most affected are treated as failures of method, not as irrational resistance.

---

## 5. Spiritual, Heritage, and Narrative Mapping

Spiritual traditions, heritage practices, and collective narratives are treated as valid ways of mapping what matters in a landscape.

**Typical practices**

- Documenting sacred sites, pilgrimage routes, burial grounds, shrines, and other places where spiritual meaning is anchored, when and only when communities consent.  
- Working with elders, faith leaders, artists, and culture‑bearers to trace lines of covenant, trauma, blessing, and taboo through space and time.  
- Analyzing liturgies, songs, stories, and ritual calendars as “maps” of who is bound to whom, for what, and where.  
- Explicitly marking zones of non‑representation—mysteries, rituals, or stories that must not be digitized, modeled, or disclosed beyond certain circles.

**Interpretation**

These mappings are not reduced to “soft data.” They are held alongside quantitative and infrastructural maps, with equal weight, in deciding what kinds of changes are permissible, desirable, or forbidden in a place. In some cases, spiritual or heritage commitments set hard constraints that models and instruments are not allowed to override, even when optimization would suggest otherwise.

---

## 6. AI‑ and Systems‑Based Experimentation

AI architectures and systems‑theoretic models are used as experimental apparatus for probing and reshaping complex spatial feedback loops.

**Typical practices**

- Deploying multi‑agent and memory‑structured AI systems (e.g., Ms. Jarvis‑type architectures) to simulate policy changes, infrastructure shifts, or new institutional forms.  
- Using live systems (e.g., commons platforms, mutual‑credit apps, DAOs) as laboratories where feedback loops between people, algorithms, and infrastructures can be observed, measured, and tuned.  
- Applying systems‑theory tools (causal loop diagrams, control‑theoretic analysis, resilience and tipping‑point analysis) to coupled ecological, economic, social, and spiritual subsystems.  
- Monitoring for drift toward harmful archetypes (for example, surveillance and behavioral nudging, hyper‑optimization for a few actors, or opaque concentration of governance power) and defining in advance how such drift will be detected.

**Interpretation**

AI and systems outputs are treated as hypotheses and instruments, not as final arbiters. Their validity is tested against field‑anchored inquiry, participatory feedback, and ethical/spiritual reflection. A model that “performs well” but contradicts lived experience, deep commitments, or agreed boundaries is considered untrustworthy. Experimentation is designed with clear exit ramps and kill‑switches so that tools can be paused, rolled back, or retired when harms or unacceptable drifts appear.

---

## 7. Braided Interpretation and Reflexivity

The most important method is not any single technique but the *braiding* of multiple strands.

**Typical practices**

- Iterating between fieldwork, modeling, mapping, and design so that each strand can challenge and refine the others.  
- Making explicit the metaphors, assumptions, and power relations baked into models and infrastructures, including which industrial systems they risk imitating.  
- Building reflexive practices into projects (journals, debriefs, audits, spiritual or ethical discernment) so that the work itself becomes an object of geographic scrutiny.  
- Periodically asking where the discipline’s own instruments are acting like new centers of extraction or authority, and what must change when that happens.

**Interpretation**

Results are only considered robust when they “make sense” across layers: when the math, the maps, the narratives, the institutional arrangements, and the testimonies of those most affected all cohere enough to support action. Where they conflict, polymathmatic geography treats that conflict as a clue about hidden structures or neglected voices, not as noise to be averaged away, and is willing to revise or abandon models and tools rather than force a premature harmony.

---

## 8. How Results Are Ultimately Read

Across all methods, outcomes are interpreted through three questions:

1. **What has changed in the actual geography of relation?**  
   Who is more or less exposed, connected, empowered, or silenced in this space, and how have flows of value, information, and obligation been rewired?

2. **How is this experienced by communities who live there?**  
   Do people report greater safety, dignity, agency, and meaning, or the opposite? Are there new harms, fears, or exclusions that the models did not foresee?

3. **What kind of world is being made or rehearsed?**  
   Does this configuration move toward the kinds of worlds the discipline is committed to exploring—worlds where entangled spaces are more just, life‑giving, and truthful—or away from them? Does it reproduce geometries of extraction and enclosure, or help compose counter‑geometries of commons, covenant, and accountability?

Polymathmatic geography is thus not only a toolkit of methods but a stance about how methods must answer to worlds, not the other way around. It measures its own success by whether its instruments can be held to account by the places and peoples they touch, and by its willingness to stop, change course, or relinquish a design when that accounting fails.

---

## 9. Appalachian Field Protocol: Staged Practice

To make these methods actionable in Appalachia, the discipline adopts a staged field protocol. The aim is to move from listening to live instrumentation without outpacing consent, safety, or local capacity. Each stage can be paused, repeated, or rolled back; progression is conditional, not automatic.

### Stage 0 – Grounding Without Instruments

**Aim:** Build a shared, place‑anchored understanding of entangled space *before* introducing new digital or financial tools.

**Practices**

- Deep field‑anchored inquiry and spiritual, heritage, and narrative mapping: walks, kitchen‑table conversations, church basements, funerals, festivals.  
- Hand‑drawn and story‑based maps of danger, care, extraction, and hope: where debt collectors come from, where mutual aid flows, where spiritual anchors and taboos sit.  
- Genealogical and institutional mapping of who has historically held power over land, labor, and story in the area.  
- Explicit conversations about **refusal**: what must not be digitized, ledgered, or made machine‑readable at all.

**Roles**

- **Elders and pastors/faith leaders** – primary interpreters of lineage, covenant, trauma, and blessing; set red lines for what cannot be modeled.  
- **Organizers and mutual‑aid leaders** – surface current networks of care and conflict.  
- **Youth and technologists** – listen first; document only with consent.

**Must not be delegated**

- Decisions about what is sacred, taboo, or closed to instruments.  
- Naming of harms, fears, and hopes; these belong to residents, not to Ms. Jarvis or a DAO.

### Stage 1 – Low‑Risk Digital Commons (No Money, No Credit)

**Aim:** Introduce a minimal digital commons focused on visibility and memory, not on transactions or credit.

**Practices**

- Launch a basic version of **The Commons** as a local story and mapping space: memorials, offers and needs, hazard reports, event listings.  
- Implement strict privacy and consent defaults; allow pseudonymity and “offline‑only” markers for sensitive content.  
- Use the platform to support existing practices (e.g., prayer chains, meal trains, benefit concerts) rather than to replace them.

**Roles**

- **Community moderators and trusted stewards** – oversee content norms, conflict resolution, and privacy enforcement.  
- **County officials and service providers** – invited in carefully, with clear boundaries, to listen and respond, not to surveil.  
- **Technologists and youth** – maintain the platform, provide training, translate between interface and elders’ needs.

**Must not be delegated**

- Final say on platform norms and sanctions (remains with community bodies, not Ms. Jarvis).  
- Decisions about forwarding data to outside agencies or firms.

### Stage 2 – Limited‑Scope MountainShares Pilots

**Aim:** Carefully test mutual‑credit and reward instruments in narrow, well‑bounded domains.

**Practices**

- Define one or two small pilot use cases (e.g., a single neighborhood, a food‑sharing circle, or a group of local merchants) with clear spatial and social boundaries.  
- Introduce MountainShares as a closed‑loop reward or mutual‑credit system tied to specific contributions (e.g., volunteer hours, local purchases, care work), *with* hard caps on balance, volume, and eligible transactions.  
- Log flows transparently and regularly review them with participants: who is earning, who is spending, where balances accumulate or go dormant.

**Evaluation criteria**

- Distribution: Are rewards reaching those doing care and commons work, or only the already‑connected?  
- Leakage: Are there unexpected ways value is leaving the loop?  
- Trust: Do participants feel more secure and recognized, or confused and exploited?

**Roles**

- **Pilot participants (residents, small businesses, churches, clinics)** – co‑design rules and define what counts as valuable contribution.  
- **Organizers and county officials** – observe, support, and document effects, but without commandeering the system.  
- **Technologists/Ms. Jarvis team** – implement caps, audits, and monitoring; explain behaviour in plain language; adjust only through agreed governance processes.

**Must not be delegated**

- Authority to redefine what counts as legitimate contribution or who is eligible to participate.  
- Decisions to expand pilot scope; these must be made by affected communities, not solely by technical or academic staff.

### Stage 3 – Conditional Integration with Policy and Infrastructure

**Aim:** Only after earlier stages meet justice and safety thresholds, selectively integrate the stack with broader institutions.

**Practices**

- Consider linking MountainShares and The Commons to local or regional infrastructures (e.g., transit passes, utility assistance, clinic scheduling, disaster response) *only* where pilots have shown clear benefits and no major harms.  
- Establish formal agreements with county or state agencies that codify data governance, limits on surveillance, and non‑retaliation for participation.  
- Use Ms. Jarvis in advisory roles (e.g., highlighting under‑served blocks, resilience corridors, or heat‑risk clusters), with human decision‑makers retaining final authority.

**Thresholds for integration**

- Demonstrated improvements in local safety, dignity, or material security, as reported by those most affected.  
- No major unresolved conflicts over privacy, bias, or exclusion.  
- Clear, community‑ratified procedures for halting or rolling back integrations that go wrong.

**Roles**

- **County and state officials** – act as partners in implementing community‑defined integrations, not as owners of the stack.  
- **Commons councils / DAO governance bodies** – hold veto power over expansions that threaten local control or violate prior red lines.  
- **Technologists and Ms. Jarvis** – provide analysis, simulation, and monitoring; surface risks; never act as autonomous decision‑makers.

**Must not be delegated**

- Ultimate decisions about land use, policing, benefits eligibility, or disciplinary actions. Ms. Jarvis may *inform* such decisions but may not make or enforce them.  
- The authority to override previously established spiritual, cultural, or genealogical constraints in the name of efficiency or growth.

---

This staged protocol is not a rigid ladder but a **safety scaffold**: it encodes the discipline’s commitment that methods and instruments must grow out of, and remain answerable to, Appalachian worlds. Progression is earned through demonstrated care, not assumed by technical capability.
